# Cache4AI
# 语义缓存

语义缓存通过理解查询的语义意义来提升缓存效率，特别适用于LLM应用。

- **GPTCache**：GitHub上的项目展示了其与LangChain和llama_index的集成
    - 链接：[GPTCache GitHub](https://github.com/zilliztech/GPTCache)
    - A Library for Creating Semantic Cache for LLM Queries，Slash Your LLM API Costs by 10x 💰, Boost Speed by 100x ⚡
    - 值得注意的是，Milvus向量数据库也是他们做的。
    - ![[Cache Layer for LLM.png]]
- **Redis的语义缓存**：
    - 链接：[Redis Blog - What is Semantic Caching?](https://redis.io/blog/what-is-semantic-caching/)
    - Redis的SemanticCache文档：2025年的文档详细说明了RedisVL如何通过向量搜索实现语义缓存，减少LLM请求。
        - 链接：[Redis Documentation - SemanticCache](https://redis.io/docs/latest/integrate/redisvl/user_guide/llmcache/)
	- Azure Managed Redis：2025年5月20日的Microsoft Learn教程展示了如何使用Azure Managed Redis进行语义缓存，结合Azure OpenAI服务提升响应速度。链接：[Microsoft Learn - Azure Managed Redis as Semantic Cache](https://learn.microsoft.com/en-us/azure/redis/tutorial-semantic-cache)
	- LangCache by Redis：2025年4月8日推出的Redis管理式语义缓存服务，优化GenAI应用和RAG管道，承诺减少90%的LLM调用。链接：[LangCache by Redis](https://redis.io/langcache/)
- **Leveraging Approximate Caching for Faster Retrieval-Augmented Generation**
	- [https://doi.org/10.1145/3721146.3721941](https://doi.org/10.1145/3721146.3721941)
	- 会议：2025年4月1日，5th Workshop on Machine Learning and Systems (co-located with ACM SIGMOD/PODS 2025)
	- 关键贡献：
		提出近似缓存技术，通过重用相似的提示来加速检索增强生成（RAG），降低LLM推理的延迟。
		在实际工作负载上实现了显著的性能提升，适合需要快速响应的AI应用。
		相关性：该论文虽然主要针对RAG，但其近似缓存技术与AI4Cache高度相关，发表在与SIGMOD相关的顶级工作坊。

### 问题：
1. 目前只有两个工程项目比较火，redis-SemanticCache（2024-7），GPTCache（2025），<span style="background:#fff88f">缺少论文支撑</span>
2. Advancing Semantic Caching for LLMs with Domain-Specific Embeddings and Synthetic Data（好像中了IPDPS）
3. MeanCache: User-Centric Semantic Cache for Large Language Model Based Web Services
4. SCALM: Towards Semantic Caching for Automated Chat Services with Large Language Models（这两个文章都是对比GPTCache的，都在arxiv上）



# AI4Cache：
1. 3L-Cache: Low Overhead and Precise Learningbased Eviction Policy for Caches
	1. https://www.usenix.org/system/files/fast25-zhou-wenbin.pdf
	2. 开源：https://github.com/optiq-lab/3L-Cache
2.  iCache: An Intelligent Cache Allocation Strategy for Multitenant in High-Performance Solid-State Disks
3. Advancements in cache management: a review of machine learning innovations for enhanced performance and security
	    - 全面综述机器学习在缓存管理中的应用，涵盖三个主要领域：
	        - **缓存替换**：讨论了从传统启发式方法到机器学习的转变，介绍了RLR（单核和四核系统性能比LRU分别提高3.25%和4.86%）、Glider（单核系统未命中率比LRU降低8.9%）、LeCaR（小缓存尺寸下性能比ARC提高18倍）、CACHEUS、PARROT和Seq2Seq（比LRU、LFU和ARC分别提高77%、65%和77%）。
	        - **边缘网络内容缓存**：包括DeepCache（使用深度LSTM预测内容流行度）、PA-Cache（使用多层RNN降低计算成本）、RL-Cache（在Akamai数据上提升缓存命中率）。
	        - **缓存安全**：讨论了机器学习在检测缓存侧信道攻击（如Flush + Reload、Flush + Flush、Specter）中的应用，模型准确率高达99.92%（Tong et al., 2020）。
	    - 分析了机器学习在硬件、边缘设备和大规模云系统中的应用，强调其适应工作负载特性和提高缓存命中率的能力。
	- **相关性**：作为2025年的综述文章，该论文涵盖了AI4Cache的最新进展，引用了大量2024和2025年的研究，适合作为研究起点。
	- **链接**：链接：[Frontiers in Artificial Intelligence](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1441250/full)
4.  https://arxiv.org/html/2501.14770v1
	1. 该研究比较了机器学习方法与传统缓存策略（如写穿、写回和 LRU 逐出）的性能，显示机器学习方法在所有工作负载下均取得了最高的缓存命中率和最长的 SSD 寿命。以下是关键性能指标的示例：

# 问题
1. 可以参考现有方法，做面向SSD的AI Cache策略
2. 性能问题，现有文章的实验多数都是在模拟。
3. 机器学习方法本身不好提升，这个我不擅长。
4. FDP：
	1. 相较于ZNS，如果你什么都不做，他就会退化为近似普通SSD。
	2. 降低写放大；
	3. 降低延迟；
	4. 在容量满时维持性能稳定。

--- 


# SSD Cache

>关于SSD装满数据时（普通SSD as Cache时），性能下降的问题：
## 因果关系
高占用率 → 可用空白区块（Free Blocks）稀缺 → 强制且低效的垃圾回收（Garbage Collection, GC） → 高写入放大（Write Amplification, WA） → 尾延迟，性能下降

## 关于GC：
1. **后台GC（Background GC / Idle-Time GC）**：这是最理想的情况。当SSD处于空闲状态时（即没有用户读写请求），控制器会利用这段时间在后台悄悄地进行垃圾回收 。此时，它可以从容地选择最优的“受害者”块（即有效页最少的块），以最小的代价整理空间，补充空白块池。这个过程对用户是透明的，几乎不影响前台性能。
2. **前台GC（Foreground GC / On-Demand GC）**：这是性能灾难的来源。当SSD处于持续高强度的写入负载下，并且内部的空白块池被耗尽时，控制器就别无选择，只能在响应用户新的写入请求的同时**强制、立即**地执行垃圾回收 。在这种情况下，用户的写入操作必须暂停，等待GC完成并释放出一个新的空白块后才能继续。这直接导致了操作延迟的急剧增加，即性能“尖峰”或卡顿

# 佐证：

1. **ScaleLFS(FAST '25)**
	1.  ScaleLFS：A Log-Structured File System with Scalable Garbage Collection for Higher Sustained Performance on Commodity SSDs
	2. 为了解决垃圾回收（GC）对“持续性能”（Sustained Performance）的严重影响。论文中的基准测试明确显示，当文件系统因<span style="background:#fff88f">空间占满而触发GC时</span>，应用程序的写入带宽会急剧下降，降幅高达68倍。其中，前台GC是导致性能骤降的直接原因
2. **FairyWREN(OSDI '24)**
	1.  FairyWREN：A Flash Cache that Reduces Writes by Unifying Cache Admission and Garbage Collection
	2. 分析得出<span style="background:#fff88f">GC是写入放大的主要来源</span>，而高写入放大直接消耗内部带宽，导致性能下降
3. **CVSS SSD(FAST '24):**
	1. 传统的 SSD 设计采用固定容量的抽象，即使在设备老化后没有，而某些NAND老化后导致实际空间已经不足，这导致了性能显著下降和可靠性问题。CVSS通过在设备老化时优雅地减少存储容量来保持高性能和可靠性
4. Observation and Optimization on Garbage Collection of Flash Memories: The View in Performance Cliff    _Micromachines_ (2021)
	1. 它正式将SSD响应时间偶尔出现的剧烈延迟尖峰定义为“性能悬崖”（Performance Cliff），并明确指出其主要原因是垃圾回收过程本身带来的高延迟。更重要的是，研究发现现代3D NAND技术由于块尺寸更大，在单次GC中需要迁移的有效页数量“高得多”，反而**加剧了性能悬崖问题**。
5. 研究显示，普通SSD在满负荷时WAF可能高达3.5，而在50%利用率下也可能超过1.3（来源：[Samsung Semiconductor, 2025](https://semiconductor.samsung.com/news-events/tech-blog/nvme-fdp-a-promising-new-ssd-data-placement-approach/)
6. 《Performance of greedy garbage collection in flash-based solid-state drives》 IBM，2010
	1. 通过数学建模和仿真，得出结论：**随着系统占用率（system occupancy）的增加，写入放大因子（write amplification）也随之增加** 。写入放大是衡量SSD内部额外写入量的指标，其数值越高，意味着SSD为完成用户写入请求而执行的内部数据迁移工作越多，从而直接导致对外表现的性能下降和寿命损耗。

**总而言之**，普通SSD在缓存中使用时：
	写放大因子较高会导致更多内部写入，加速NAND闪存的磨损，缩短寿命；
	高WAF还会增加垃圾收集的频率，降低性能；
	为了保证垃圾回收效率，需要过量配置（OP）作为有”誊写“的空间，牺牲实际可用容量。

